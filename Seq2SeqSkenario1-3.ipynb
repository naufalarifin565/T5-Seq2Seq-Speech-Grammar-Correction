{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o40G0uRTYxV"
      },
      "source": [
        "SKENARIO 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATA"
      ],
      "metadata": {
        "id": "-2a7A2MAp6k7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUdqts5FU6Ye"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Skenario 1 (errant).csv\")\n",
        "df = df.dropna()\n",
        "df = df[['input', 'target']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "gTS_csPBugnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FIjn4w2U_cX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "\n",
        "# Preprocessing fungsi\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghilangkan tanda baca\n",
        "    text = re.sub(r'\\d+', '', text)  # Menghilangkan angka\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Menghilangkan spasi berlebih\n",
        "    return text.strip()\n",
        "\n",
        "# Kita terapkan preprocessing\n",
        "df['input'] = df['input'].astype(str).apply(clean_text)\n",
        "df['target'] = df['target'].astype(str).apply(clean_text)\n",
        "\n",
        "df['input'].to_csv(\"src.txt\", index=False, header=False)\n",
        "df['target'].to_csv(\"tgt.txt\", index=False, header=False)\n",
        "\n",
        "# Latih tokenizer SentencePiece\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='src.txt,tgt.txt',\n",
        "    model_prefix='tokenizer',\n",
        "    vocab_size=1603,\n",
        "    pad_id=0,\n",
        "    bos_id=1,\n",
        "    eos_id=2,\n",
        "    unk_id=3\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "sp = spm.SentencePieceProcessor(model_file='tokenizer.model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mempersiapkan data teks (input dan target) dalam format tensor numerik agar bisa digunakan oleh model Transformer (atau Seq2Seq lainnya)."
      ],
      "metadata": {
        "id": "RibfY-EXutOE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd0GlnjrVQN9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, src_texts, tgt_texts, tokenizer, max_len=64):\n",
        "        self.src_texts = src_texts\n",
        "        self.tgt_texts = tgt_texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_ids = [1] + self.tokenizer.encode(self.src_texts[idx]) + [2]\n",
        "        tgt_ids = [1] + self.tokenizer.encode(self.tgt_texts[idx]) + [2]\n",
        "\n",
        "        src_ids = src_ids[:self.max_len] + [0] * (self.max_len - len(src_ids))\n",
        "        tgt_ids = tgt_ids[:self.max_len] + [0] * (self.max_len - len(tgt_ids))\n",
        "\n",
        "        return {\n",
        "            'src_ids': torch.tensor(src_ids),\n",
        "            'trg_ids': torch.tensor(tgt_ids)\n",
        "        }\n",
        "\n",
        "# Split data\n",
        "train_src, val_src, train_tgt, val_tgt = train_test_split(df['input'], df['target'], test_size=0.1)\n",
        "\n",
        "# Dataset\n",
        "train_data = GrammarDataset(train_src.tolist(), train_tgt.tolist(), sp)\n",
        "val_data = GrammarDataset(val_src.tolist(), val_tgt.tolist(), sp)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arsitektur model Transformer berbasis Seq2Seq"
      ],
      "metadata": {
        "id": "4JmnxE1Bx3_P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF7mcAaTWnoT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, num_heads=8, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.transformer = nn.Transformer(d_model=embed_dim, nhead=num_heads, num_encoder_layers=num_layers,\n",
        "                                          num_decoder_layers=num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        src_emb = self.embedding(src)\n",
        "        tgt_emb = self.embedding(tgt)\n",
        "\n",
        "        out = self.transformer(src_emb.permute(1, 0, 2), tgt_emb.permute(1, 0, 2),\n",
        "                               src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "        return self.fc(out.permute(1, 0, 2))  # (batch, seq, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqZSLP7DWzgn",
        "outputId": "1c14c336-1654-4eac-88a8-52c40f7a7cc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Train Loss: 6.6164 | Val Loss: 5.9745\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 5.6819 | Val Loss: 5.3361\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 5.1113 | Val Loss: 4.9198\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 4.6587 | Val Loss: 4.5637\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 4.2716 | Val Loss: 4.2821\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 3.9345 | Val Loss: 4.0369\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 3.6537 | Val Loss: 3.8417\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 3.3762 | Val Loss: 3.6578\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 3.1627 | Val Loss: 3.4903\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 2.9441 | Val Loss: 3.3650\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 2.7715 | Val Loss: 3.2314\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 2.5683 | Val Loss: 3.1249\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 2.4134 | Val Loss: 3.0063\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 2.2504 | Val Loss: 2.8917\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 2.0988 | Val Loss: 2.7944\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 1.9556 | Val Loss: 2.7073\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 1.8238 | Val Loss: 2.6414\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 1.6991 | Val Loss: 2.5498\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 1.5809 | Val Loss: 2.5049\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 1.4634 | Val Loss: 2.4447\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 1.3397 | Val Loss: 2.3945\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 1.2492 | Val Loss: 2.3348\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 1.1676 | Val Loss: 2.2928\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 1.1000 | Val Loss: 2.2471\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 1.0281 | Val Loss: 2.2044\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = Seq2SeqTransformer(vocab_size=2059).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "# Use optim.Adam instead of torch.optim.Adam for clarity and consistency, though torch.optim works\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        src = batch['src_ids'].to('cuda')\n",
        "        tgt = batch['trg_ids'].to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt[:, :-1])\n",
        "        loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate_loss(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            src = batch['src_ids'].to('cuda')\n",
        "            tgt = batch['trg_ids'].to('cuda')\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "for epoch in range(25):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = evaluate_loss(model, val_loader)\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDKjfHrWWzjC"
      },
      "outputs": [],
      "source": [
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBUhpUpgaNDr",
        "outputId": "9fffc558-4be0-4a9d-8d7f-a256071488b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ce0a9baae81f436a41aa68932733f3a84a04c6a620076083702f9444bcb70659\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "wordnet not found. Attempting to download wordnet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU: 0.3673\n",
            "METEOR: 0.5490\n",
            "ROUGE-1: 0.6183\n",
            "ROUGE-2: 0.4652\n",
            "ROUGE-L: 0.5967\n",
            "Exact Match: 0.2012\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "import nltk\n",
        "# Remove the incorrect exception handling for DownloadError\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    print(\"wordnet not found. Attempting to download wordnet...\")\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def evaluate_metrics(model, data, tokenizer, max_len=64):\n",
        "    bleu_scores, meteor_scores, em_scores = [], [], []\n",
        "    r1, r2, rl = [], [], []\n",
        "\n",
        "    for idx in range(len(data)):\n",
        "        # Get sample from dataset\n",
        "        batch = data[idx]\n",
        "\n",
        "        # Dekode dan bersihkan kalimat target dan kalimat yang diprediksi\n",
        "        # Dengan asumsi item batch sudah berupa tensor, ubah ke daftar sebelum mendekode\n",
        "        src = tokenizer.decode(batch['src_ids'].tolist()).replace('<pad>', '').strip()\n",
        "        tgt = tokenizer.decode(batch['trg_ids'].tolist()).replace('<pad>', '').strip()\n",
        "\n",
        "        pred = correct(model, src).strip()\n",
        "\n",
        "        # Tokenize for metrics that require it\n",
        "        tgt_tokens = tgt.split()\n",
        "        pred_tokens = pred.split()\n",
        "        bleu_scores.append(sentence_bleu([tgt_tokens], pred_tokens))\n",
        "        meteor_scores.append(meteor_score([tgt_tokens], pred_tokens))\n",
        "        em_scores.append(int(tgt == pred))\n",
        "\n",
        "        scores = scorer.score(tgt, pred)\n",
        "        r1.append(scores['rouge1'].fmeasure)\n",
        "        r2.append(scores['rouge2'].fmeasure)\n",
        "        rl.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "    # Handle potential division by zero if data is empty\n",
        "    num_samples = len(bleu_scores)\n",
        "    if num_samples == 0:\n",
        "        return {\n",
        "            \"BLEU\": 0.0,\n",
        "            \"METEOR\": 0.0,\n",
        "            \"ROUGE-1\": 0.0,\n",
        "            \"ROUGE-2\": 0.0,\n",
        "            \"ROUGE-L\": 0.0,\n",
        "            \"Exact Match\": 0.0,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": sum(bleu_scores)/num_samples,\n",
        "        \"METEOR\": sum(meteor_scores)/num_samples,\n",
        "        \"ROUGE-1\": sum(r1)/num_samples,\n",
        "        \"ROUGE-2\": sum(r2)/num_samples,\n",
        "        \"ROUGE-L\": sum(rl)/num_samples,\n",
        "        \"Exact Match\": sum(em_scores)/num_samples,\n",
        "    }\n",
        "\n",
        "metrics = evaluate_metrics(model, val_data, sp)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjm4R_JPTsUu"
      },
      "source": [
        "SKENARIO 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATA"
      ],
      "metadata": {
        "id": "X7YTun1Er62P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FzeML15XP0H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Skenario 2 (shadow labeling & augmentasi).csv\")\n",
        "df = df.dropna()\n",
        "df = df[['input', 'target']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "7mTpAzcTumVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0NOEkgAXP6N"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "\n",
        "# Preprocessing fungsi\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghilangkan tanda baca\n",
        "    text = re.sub(r'\\d+', '', text)  # Menghilangkan angka\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Menghilangkan spasi berlebih\n",
        "    return text.strip()\n",
        "\n",
        "# Kita terapkan preprocessing\n",
        "df['input'] = df['input'].astype(str).apply(clean_text)\n",
        "df['target'] = df['target'].astype(str).apply(clean_text)\n",
        "\n",
        "df['input'].to_csv(\"src.txt\", index=False, header=False)\n",
        "df['target'].to_csv(\"tgt.txt\", index=False, header=False)\n",
        "\n",
        "# Latih tokenizer SentencePiece\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='src.txt,tgt.txt',\n",
        "    model_prefix='tokenizer',\n",
        "    vocab_size=1603,\n",
        "    pad_id=0,\n",
        "    bos_id=1,\n",
        "    eos_id=2,\n",
        "    unk_id=3\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "sp = spm.SentencePieceProcessor(model_file='tokenizer.model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mempersiapkan data teks (input dan target) dalam format tensor numerik agar bisa digunakan oleh model Transformer (atau Seq2Seq lainnya)."
      ],
      "metadata": {
        "id": "D4Z8lzmNvKRz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R2YOIpGXP9w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, src_texts, tgt_texts, tokenizer, max_len=64):\n",
        "        self.src_texts = src_texts\n",
        "        self.tgt_texts = tgt_texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_ids = [1] + self.tokenizer.encode(self.src_texts[idx]) + [2]\n",
        "        tgt_ids = [1] + self.tokenizer.encode(self.tgt_texts[idx]) + [2]\n",
        "\n",
        "        src_ids = src_ids[:self.max_len] + [0] * (self.max_len - len(src_ids))\n",
        "        tgt_ids = tgt_ids[:self.max_len] + [0] * (self.max_len - len(tgt_ids))\n",
        "\n",
        "        return {\n",
        "            'src_ids': torch.tensor(src_ids),\n",
        "            'trg_ids': torch.tensor(tgt_ids)\n",
        "        }\n",
        "\n",
        "# Split data\n",
        "train_src, val_src, train_tgt, val_tgt = train_test_split(df['input'], df['target'], test_size=0.1)\n",
        "\n",
        "# Dataset\n",
        "train_data = GrammarDataset(train_src.tolist(), train_tgt.tolist(), sp)\n",
        "val_data = GrammarDataset(val_src.tolist(), val_tgt.tolist(), sp)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arsitektur model Transformer berbasis Seq2Seq"
      ],
      "metadata": {
        "id": "cFdvrJklyBTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPurGd6KXQPj"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, num_heads=8, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.transformer = nn.Transformer(d_model=embed_dim, nhead=num_heads, num_encoder_layers=num_layers,\n",
        "                                          num_decoder_layers=num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        src_emb = self.embedding(src)\n",
        "        tgt_emb = self.embedding(tgt)\n",
        "\n",
        "        out = self.transformer(src_emb.permute(1, 0, 2), tgt_emb.permute(1, 0, 2),\n",
        "                               src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "        return self.fc(out.permute(1, 0, 2))  # (batch, seq, vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LZrliREXQSg",
        "outputId": "7f9ae421-6266-4935-ec5d-3153f1b52aec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Train Loss: 6.5647 | Val Loss: 5.9907\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 5.7174 | Val Loss: 5.3385\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 5.0977 | Val Loss: 4.8774\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 4.6114 | Val Loss: 4.4473\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 4.2123 | Val Loss: 4.1463\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 3.8609 | Val Loss: 3.8631\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 3.5563 | Val Loss: 3.6145\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 3.2730 | Val Loss: 3.3958\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 3.0168 | Val Loss: 3.1983\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 2.7844 | Val Loss: 3.0144\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 2.5685 | Val Loss: 2.8478\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 2.3628 | Val Loss: 2.7028\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 2.1852 | Val Loss: 2.5687\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 2.0204 | Val Loss: 2.4479\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 1.8551 | Val Loss: 2.3530\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 1.7151 | Val Loss: 2.2428\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 1.5774 | Val Loss: 2.1491\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 1.4497 | Val Loss: 2.0567\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 1.3349 | Val Loss: 2.0007\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 1.2203 | Val Loss: 1.9071\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 1.1069 | Val Loss: 1.8631\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 1.0173 | Val Loss: 1.7847\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 0.9320 | Val Loss: 1.7252\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 0.8477 | Val Loss: 1.6900\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 0.7706 | Val Loss: 1.6302\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim # Import optim explicitly\n",
        "\n",
        "model = Seq2SeqTransformer(vocab_size=2059).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "# Use optim.Adam instead of torch.optim.Adam for clarity and consistency, though torch.optim works\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        src = batch['src_ids'].to('cuda')\n",
        "        tgt = batch['trg_ids'].to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt[:, :-1])\n",
        "        loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate_loss(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            src = batch['src_ids'].to('cuda')\n",
        "            tgt = batch['trg_ids'].to('cuda')\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "for epoch in range(25):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = evaluate_loss(model, val_loader)\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLKLAIbbXQV4"
      },
      "outputs": [],
      "source": [
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbs4Nw-VXQZL",
        "outputId": "cf33c8a2-471d-476d-a78e-d9ccca010c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "wordnet not found. Attempting to download wordnet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU: 0.4598\n",
            "METEOR: 0.6636\n",
            "ROUGE-1: 0.7075\n",
            "ROUGE-2: 0.5816\n",
            "ROUGE-L: 0.6948\n",
            "Exact Match: 0.3894\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "import nltk\n",
        "# Remove the incorrect exception handling for DownloadError\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    print(\"wordnet not found. Attempting to download wordnet...\")\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def evaluate_metrics(model, data, tokenizer, max_len=64):\n",
        "    bleu_scores, meteor_scores, em_scores = [], [], []\n",
        "    r1, r2, rl = [], [], []\n",
        "\n",
        "    for idx in range(len(data)):\n",
        "        # Get sample from dataset\n",
        "        batch = data[idx]\n",
        "\n",
        "        # Dekode dan bersihkan kalimat target dan kalimat yang diprediksi\n",
        "        # Dengan asumsi item batch sudah berupa tensor, ubah ke daftar sebelum mendekode\n",
        "        src = tokenizer.decode(batch['src_ids'].tolist()).replace('<pad>', '').strip()\n",
        "        tgt = tokenizer.decode(batch['trg_ids'].tolist()).replace('<pad>', '').strip()\n",
        "\n",
        "        pred = correct(model, src).strip()\n",
        "\n",
        "        # Tokenize for metrics that require it\n",
        "        tgt_tokens = tgt.split()\n",
        "        pred_tokens = pred.split()\n",
        "        bleu_scores.append(sentence_bleu([tgt_tokens], pred_tokens))\n",
        "        meteor_scores.append(meteor_score([tgt_tokens], pred_tokens))\n",
        "        em_scores.append(int(tgt == pred))\n",
        "\n",
        "        scores = scorer.score(tgt, pred)\n",
        "        r1.append(scores['rouge1'].fmeasure)\n",
        "        r2.append(scores['rouge2'].fmeasure)\n",
        "        rl.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "    # Handle potential division by zero if data is empty\n",
        "    num_samples = len(bleu_scores)\n",
        "    if num_samples == 0:\n",
        "        return {\n",
        "            \"BLEU\": 0.0,\n",
        "            \"METEOR\": 0.0,\n",
        "            \"ROUGE-1\": 0.0,\n",
        "            \"ROUGE-2\": 0.0,\n",
        "            \"ROUGE-L\": 0.0,\n",
        "            \"Exact Match\": 0.0,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": sum(bleu_scores)/num_samples,\n",
        "        \"METEOR\": sum(meteor_scores)/num_samples,\n",
        "        \"ROUGE-1\": sum(r1)/num_samples,\n",
        "        \"ROUGE-2\": sum(r2)/num_samples,\n",
        "        \"ROUGE-L\": sum(rl)/num_samples,\n",
        "        \"Exact Match\": sum(em_scores)/num_samples,\n",
        "    }\n",
        "\n",
        "metrics = evaluate_metrics(model, val_data, sp)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui-5nX8BnNrn"
      },
      "source": [
        "SKENARIO 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eA34wL9nPII"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Skenario 3 (pure dari dataset grammar correction).csv\")\n",
        "df = df.dropna()\n",
        "df = df[['input', 'target']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "too-9sg4up6n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--vN84GpnPKz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece as spm\n",
        "import re\n",
        "\n",
        "# Preprocessing fungsi\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghilangkan tanda baca\n",
        "    text = re.sub(r'\\d+', '', text)  # Menghilangkan angka\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Menghilangkan spasi berlebih\n",
        "    return text.strip()\n",
        "\n",
        "# Kita terapkan preprocessing\n",
        "df['input'] = df['input'].astype(str).apply(clean_text)\n",
        "df['target'] = df['target'].astype(str).apply(clean_text)\n",
        "\n",
        "df['input'].to_csv(\"src.txt\", index=False, header=False)\n",
        "df['target'].to_csv(\"tgt.txt\", index=False, header=False)\n",
        "\n",
        "# Latih tokenizer SentencePiece\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='src.txt,tgt.txt',\n",
        "    model_prefix='tokenizer',\n",
        "    vocab_size=1603,\n",
        "    pad_id=0,\n",
        "    bos_id=1,\n",
        "    eos_id=2,\n",
        "    unk_id=3\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "sp = spm.SentencePieceProcessor(model_file='tokenizer.model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mempersiapkan data teks (input dan target) dalam format tensor numerik agar bisa digunakan oleh model Transformer (atau Seq2Seq lainnya)."
      ],
      "metadata": {
        "id": "bK9-sTcavSMh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcpV4XqtnPNm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, src_texts, tgt_texts, tokenizer, max_len=64):\n",
        "        self.src_texts = src_texts\n",
        "        self.tgt_texts = tgt_texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_ids = [1] + self.tokenizer.encode(self.src_texts[idx]) + [2]\n",
        "        tgt_ids = [1] + self.tokenizer.encode(self.tgt_texts[idx]) + [2]\n",
        "\n",
        "        src_ids = src_ids[:self.max_len] + [0] * (self.max_len - len(src_ids))\n",
        "        tgt_ids = tgt_ids[:self.max_len] + [0] * (self.max_len - len(tgt_ids))\n",
        "\n",
        "        return {\n",
        "            'src_ids': torch.tensor(src_ids),\n",
        "            'trg_ids': torch.tensor(tgt_ids)\n",
        "        }\n",
        "\n",
        "# Split data\n",
        "train_src, val_src, train_tgt, val_tgt = train_test_split(df['input'], df['target'], test_size=0.1)\n",
        "\n",
        "# Dataset\n",
        "train_data = GrammarDataset(train_src.tolist(), train_tgt.tolist(), sp)\n",
        "val_data = GrammarDataset(val_src.tolist(), val_tgt.tolist(), sp)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arsitektur model Transformer berbasis Seq2Seq"
      ],
      "metadata": {
        "id": "9PoQG59UyaEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Agj4B4anPQF"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=256, num_heads=8, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.transformer = nn.Transformer(d_model=embed_dim, nhead=num_heads, num_encoder_layers=num_layers,\n",
        "                                          num_decoder_layers=num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        src_emb = self.embedding(src)\n",
        "        tgt_emb = self.embedding(tgt)\n",
        "\n",
        "        out = self.transformer(src_emb.permute(1, 0, 2), tgt_emb.permute(1, 0, 2),\n",
        "                               src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "        return self.fc(out.permute(1, 0, 2))  # (batch, seq, vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu8_-OMZnPSr",
        "outputId": "af53e686-37e1-47de-bd7a-7b512368d8e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Train Loss: 6.5965 | Val Loss: 5.9687\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 5.6902 | Val Loss: 5.3024\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 5.0949 | Val Loss: 4.8349\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 4.6400 | Val Loss: 4.4632\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 4.2560 | Val Loss: 4.1601\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 3.9515 | Val Loss: 3.9216\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 3.6725 | Val Loss: 3.6929\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 3.4115 | Val Loss: 3.4952\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 3.1834 | Val Loss: 3.3245\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 2.9597 | Val Loss: 3.1358\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 2.7496 | Val Loss: 2.9890\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 2.5797 | Val Loss: 2.8514\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 2.3850 | Val Loss: 2.7358\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 2.2352 | Val Loss: 2.6228\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 2.1079 | Val Loss: 2.5282\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 1.9453 | Val Loss: 2.4163\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 1.8241 | Val Loss: 2.3436\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 1.7132 | Val Loss: 2.2467\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 1.5666 | Val Loss: 2.1899\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 1.4610 | Val Loss: 2.1211\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 1.3656 | Val Loss: 2.0726\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 1.2598 | Val Loss: 2.0089\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 1.2118 | Val Loss: 1.9652\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 1.0850 | Val Loss: 1.9010\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 1.0168 | Val Loss: 1.8737\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = Seq2SeqTransformer(vocab_size=2059).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "# Use optim.Adam instead of torch.optim.Adam for clarity and consistency, though torch.optim works\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        src = batch['src_ids'].to('cuda')\n",
        "        tgt = batch['trg_ids'].to('cuda')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt[:, :-1])\n",
        "        loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate_loss(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            src = batch['src_ids'].to('cuda')\n",
        "            tgt = batch['trg_ids'].to('cuda')\n",
        "            output = model(src, tgt[:, :-1])\n",
        "            loss = criterion(output.reshape(-1, 2059), tgt[:, 1:].reshape(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "for epoch in range(25):\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss = evaluate_loss(model, val_loader)\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nssTZMqnPVE"
      },
      "outputs": [],
      "source": [
        "def correct(model, sentence):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        src_ids = [1] + sp.encode(sentence) + [2]\n",
        "        src_ids = src_ids[:64] + [0]*(64 - len(src_ids))\n",
        "        src_tensor = torch.tensor([src_ids]).to('cuda')\n",
        "\n",
        "        tgt_ids = [1]\n",
        "        for _ in range(64):\n",
        "            tgt_tensor = torch.tensor([tgt_ids]).to('cuda')\n",
        "            output = model(src_tensor, tgt_tensor)\n",
        "            next_token = output[0, -1].argmax(-1).item()\n",
        "            if next_token == 2 or len(tgt_ids) >= 64:\n",
        "                break\n",
        "            tgt_ids.append(next_token)\n",
        "\n",
        "        return sp.decode(tgt_ids[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eDpAf-NwnPYb",
        "outputId": "820a17db-1b5f-479a-9cfa-136d6430fd9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "wordnet not found. Attempting to download wordnet...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU: 0.3431\n",
            "METEOR: 0.5491\n",
            "ROUGE-1: 0.6039\n",
            "ROUGE-2: 0.4488\n",
            "ROUGE-L: 0.5845\n",
            "Exact Match: 0.1890\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "import nltk\n",
        "# Remove the incorrect exception handling for DownloadError\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    print(\"wordnet not found. Attempting to download wordnet...\")\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "def evaluate_metrics(model, data, tokenizer, max_len=64):\n",
        "    bleu_scores, meteor_scores, em_scores = [], [], []\n",
        "    r1, r2, rl = [], [], []\n",
        "\n",
        "    for idx in range(len(data)):\n",
        "        # Get sample from dataset\n",
        "        batch = data[idx]\n",
        "\n",
        "        # Dekode dan bersihkan kalimat target dan kalimat yang diprediksi\n",
        "        # Dengan asumsi item batch sudah berupa tensor, ubah ke daftar sebelum mendekode\n",
        "        src = tokenizer.decode(batch['src_ids'].tolist()).replace('<pad>', '').strip()\n",
        "        tgt = tokenizer.decode(batch['trg_ids'].tolist()).replace('<pad>', '').strip()\n",
        "\n",
        "        pred = correct(model, src).strip()\n",
        "\n",
        "        # Tokenize for metrics that require it\n",
        "        tgt_tokens = tgt.split()\n",
        "        pred_tokens = pred.split()\n",
        "        bleu_scores.append(sentence_bleu([tgt_tokens], pred_tokens))\n",
        "        meteor_scores.append(meteor_score([tgt_tokens], pred_tokens))\n",
        "        em_scores.append(int(tgt == pred))\n",
        "\n",
        "        scores = scorer.score(tgt, pred)\n",
        "        r1.append(scores['rouge1'].fmeasure)\n",
        "        r2.append(scores['rouge2'].fmeasure)\n",
        "        rl.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "    # Handle potential division by zero if data is empty\n",
        "    num_samples = len(bleu_scores)\n",
        "    if num_samples == 0:\n",
        "        return {\n",
        "            \"BLEU\": 0.0,\n",
        "            \"METEOR\": 0.0,\n",
        "            \"ROUGE-1\": 0.0,\n",
        "            \"ROUGE-2\": 0.0,\n",
        "            \"ROUGE-L\": 0.0,\n",
        "            \"Exact Match\": 0.0,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": sum(bleu_scores)/num_samples,\n",
        "        \"METEOR\": sum(meteor_scores)/num_samples,\n",
        "        \"ROUGE-1\": sum(r1)/num_samples,\n",
        "        \"ROUGE-2\": sum(r2)/num_samples,\n",
        "        \"ROUGE-L\": sum(rl)/num_samples,\n",
        "        \"Exact Match\": sum(em_scores)/num_samples,\n",
        "    }\n",
        "\n",
        "metrics = evaluate_metrics(model, val_data, sp)\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}